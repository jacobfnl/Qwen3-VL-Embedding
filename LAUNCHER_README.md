# Multimodal File Launcher

A keyboard-launchable multimodal file search tool using Qwen3-VL embeddings. Search for files by describing their content in natural language or by providing a reference image, rather than relying on filenames or paths.

## Features

- **üé® Multimodal Search**: Search using natural language descriptions or reference images
- **‚å®Ô∏è Keyboard Shortcuts**: Global keyboard shortcut for quick access (System76-style)
- **üîç Semantic Understanding**: Powered by Qwen3-VL embeddings for deep content understanding
- **üìÅ Offline Indexing**: Build local indexes of your files with multimodal embeddings
- **üñºÔ∏è Visual Previews**: Lightweight previews with text snippets or image thumbnails
- **üéØ High Accuracy**: Semantic similarity search returning the most relevant files

## Installation

The multimodal file launcher is included in the main package. Install dependencies:

```bash
# Install dependencies
uv pip install gradio pynput pillow faiss-cpu tqdm llama-cpp-python
```

Or update all dependencies:
```bash
bash scripts/setup_environment.sh
```

### Download Models

You can use either full-precision or quantized models:

**Full-Precision Models (Multimodal Support):**
```bash
huggingface-cli download Qwen/Qwen3-VL-Embedding-2B --local-dir ./models/Qwen3-VL-Embedding-2B
```

**Quantized GGUF Models (Text-Only, Memory Efficient):**
```bash
# Download quantized model (Q4_K_M is recommended for balance of size and quality)
huggingface-cli download DevQuasar/Qwen.Qwen3-VL-Embedding-2B-GGUF \
    Qwen3-VL-Embedding-2B-Q4_K_M.gguf \
    --local-dir ./models/gguf/
```

**Quantization Options:**
- `Q4_K_M`: Recommended - good balance (4-bit, ~1.5GB)
- `Q5_K_M`: Higher quality (5-bit, ~1.8GB)
- `Q8_0`: Best quality (8-bit, ~2.5GB)
- See [DevQuasar/Qwen.Qwen3-VL-Embedding-2B-GGUF](https://huggingface.co/DevQuasar/Qwen.Qwen3-VL-Embedding-2B-GGUF) for all options

## Quick Start

### 1. Index Your Files

First, index a directory containing files you want to search:

**Using Full-Precision Model (supports images):**
```bash
python launcher.py index /path/to/your/documents --model ./models/Qwen3-VL-Embedding-2B
```

**Using Quantized GGUF Model (text-only, memory efficient):**
```bash
python launcher.py index /path/to/your/documents --model ./models/gguf/Qwen3-VL-Embedding-2B-Q4_K_M.gguf --quantized
```

This will:
- Scan the directory for supported files (text and images)
- Generate multimodal embeddings for each file
- Store the index locally in `.file_launcher_index/`

Supported file types:
- **Text files**: `.txt`, `.md`, `.py`, `.js`, `.java`, `.cpp`, `.json`, `.yaml`, `.html`, `.css`, etc.
- **Image files**: `.jpg`, `.png`, `.gif`, `.bmp`, `.webp`, `.tiff` (full-precision model only)

### 2. Launch the Search UI

Launch the Gradio interface:

**Using Full-Precision Model:**
```bash
python launcher.py launch --model ./models/Qwen3-VL-Embedding-2B
```

**Using Quantized GGUF Model (recommended for CPU):**
```bash
python launcher.py launch --model ./models/gguf/Qwen3-VL-Embedding-2B-Q4_K_M.gguf --quantized --device cpu
```

The UI will open in your browser at `http://localhost:7860`

### 3. Search Your Files

**Text Search Tab:**
- Enter a natural language description of what you're looking for
- Example: "Python code for machine learning"
- Example: "Configuration file with database settings"

**Image Search Tab:**
- Upload a reference image
- Find similar images or related content

## Keyboard Shortcut Mode

Launch with a global keyboard shortcut (Ctrl+Alt+F by default):

```bash
python launcher.py launch --model ./models/Qwen3-VL-Embedding-2B --keyboard-shortcut "<ctrl>+<alt>+f"
```

Now press `Ctrl+Alt+F` from anywhere on your system to open the search interface!

**Note**: Global keyboard shortcuts may require special permissions on some systems (e.g., accessibility permissions on macOS).

## Command Reference

### Index Command

Index files in a directory:

```bash
python launcher.py index <directory> [options]

Options:
  --no-recursive          Do not index subdirectories
  --index-dir DIR        Custom index directory (default: .file_launcher_index)
  --model MODEL          Model name, path, or GGUF file (default: Qwen/Qwen3-VL-Embedding-2B)
  --device DEVICE        Device to use: cuda or cpu (default: auto-detect)
  --quantized            Use quantized GGUF model (auto-detected for .gguf files)
```

### Launch Command

Launch the search UI:

```bash
python launcher.py launch [options]

Options:
  --index-dir DIR               Index directory (default: .file_launcher_index)
  --port PORT                   Server port (default: 7860)
  --share                       Create a public link
  --keyboard-shortcut SHORTCUT  Enable keyboard shortcut (e.g., "<ctrl>+<alt>+f")
  --model MODEL                 Model name, path, or GGUF file
  --device DEVICE               Device to use: cuda or cpu
  --quantized                   Use quantized GGUF model
```

### Info Command

Show index information:

```bash
python launcher.py info [options]

Options:
  --index-dir DIR        Index directory (default: .file_launcher_index)
```

### Clear Command

Clear the index:

```bash
python launcher.py clear [options]

Options:
  --index-dir DIR        Index directory (default: .file_launcher_index)
```

## Usage Examples

### Example 1: Index and Search Code Repository

```bash
# Index your code repository
python launcher.py index ~/projects/my-app --model ./models/Qwen3-VL-Embedding-2B

# Launch with keyboard shortcut
python launcher.py launch --model ./models/Qwen3-VL-Embedding-2B --keyboard-shortcut "<ctrl>+<alt>+f"

# Search examples:
# - "authentication logic"
# - "database connection code"
# - "configuration files"
```

### Example 2: Search Document Collection

```bash
# Index documents
python launcher.py index ~/Documents --model ./models/Qwen3-VL-Embedding-2B

# Launch UI
python launcher.py launch --model ./models/Qwen3-VL-Embedding-2B

# Search examples:
# - "budget report for Q4"
# - "meeting notes about the project"
# - "invoice from last month"
```

### Example 3: Image Collection Search

```bash
# Index photo library
python launcher.py index ~/Pictures --model ./models/Qwen3-VL-Embedding-2B

# Launch UI
python launcher.py launch --model ./models/Qwen3-VL-Embedding-2B

# Search with:
# - Text: "sunset on the beach"
# - Image: Upload a reference photo to find similar images
```

## Architecture

The multimodal file launcher consists of several integrated components working together to provide semantic file search:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         User Interface Layer                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  CLI (launcher.py)‚îÇ        ‚îÇ   Gradio UI (ui.py)              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ index          ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   ‚Ä¢ Text Search Tab              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ launch         ‚îÇ        ‚îÇ   ‚Ä¢ Image Search Tab             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ info/clear     ‚îÇ        ‚îÇ   ‚Ä¢ Results Display              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ           ‚îÇ                             ‚îÇ                            ‚îÇ
‚îÇ           ‚îÇ                             ‚îÇ                            ‚îÇ
‚îÇ           ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                            ‚îÇ
‚îÇ           ‚îÇ    ‚îÇ                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ    ‚îÇ
            ‚ñº    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      Core Application Layer                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  File Indexer (indexer.py) ‚îÇ    ‚îÇ Search Engine             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Directory Scanning      ‚îÇ    ‚îÇ (search_engine.py)        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ File Type Detection     ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ Query Processing        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Content Extraction      ‚îÇ    ‚îÇ ‚Ä¢ Similarity Calculation  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Batch Processing        ‚îÇ    ‚îÇ ‚Ä¢ Result Ranking          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Incremental Updates     ‚îÇ    ‚îÇ ‚Ä¢ Top-K Selection         ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ            ‚îÇ                                  ‚ñ≤                      ‚îÇ
‚îÇ            ‚îÇ                                  ‚îÇ                      ‚îÇ
‚îÇ            ‚ñº                                  ‚îÇ                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ                      ‚îÇ
‚îÇ  ‚îÇ     Local Index Storage                 ‚îÇ ‚îÇ                      ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ file_index.json (metadata)           ‚îÇ‚îÄ‚îò                      ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ embeddings.npy (vectors)             ‚îÇ                        ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Hash-based change detection          ‚îÇ                        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       Embedding Layer                                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Qwen3VLEmbedder         ‚îÇ    ‚îÇ  QuantizedEmbedder           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  (Full Model)            ‚îÇ    ‚îÇ  (GGUF/llama-cpp)            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Text Embeddings       ‚îÇ    ‚îÇ  ‚Ä¢ Text-Only Embeddings      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Image Embeddings      ‚îÇ    ‚îÇ  ‚Ä¢ 4-8x Memory Reduction     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Video Embeddings      ‚îÇ    ‚îÇ  ‚Ä¢ CPU Optimized             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ GPU Acceleration      ‚îÇ    ‚îÇ  ‚Ä¢ Q4_K_M, Q5_K_M, Q8_0      ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ            ‚îÇ                                  ‚îÇ                      ‚îÇ
‚îÇ            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îÇ
‚îÇ                           ‚îÇ                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îÇ  Qwen3-VL Base  ‚îÇ
                   ‚îÇ     Models      ‚îÇ
                   ‚îÇ  (HuggingFace)  ‚îÇ
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Optional: Keyboard Shortcuts                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  KeyboardShortcutHandler (keyboard_handler.py)             ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Global Hotkey Listener (Ctrl+Alt+F)                     ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ UI Launcher with Thread Safety                          ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Graceful Fallback (no X server)                         ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Component Descriptions

**1. File Indexer** (`src/launcher/indexer.py`)
   - Scans directories recursively for supported file types
   - Extracts content from text files and metadata from images
   - Generates embeddings via the embedding layer
   - Stores results in local JSON + NumPy format
   - Uses hash-based change detection for incremental updates

**2. Search Engine** (`src/launcher/search_engine.py`)
   - Processes text or image queries through embedder
   - Computes cosine similarity between query and indexed embeddings
   - Ranks results by similarity score
   - Returns top-K most relevant files with metadata

**3. UI Layer** (`src/launcher/ui.py`)
   - Gradio-based web interface with dual tabs
   - Text search: natural language query input
   - Image search: reference image upload
   - Results display with previews and similarity scores

**4. Keyboard Handler** (`src/launcher/keyboard_handler.py`)
   - Optional global keyboard shortcut support
   - Thread-safe UI launching with mutex protection
   - Gracefully handles environments without X server

**5. Embedding Layer**
   - **Qwen3VLEmbedder**: Full-precision multimodal model
   - **QuantizedEmbedder**: Memory-efficient GGUF wrapper
   - Auto-selection based on model file format

### Data Flow

1. **Indexing Flow**:
   ```
   User Files ‚Üí File Indexer ‚Üí Embedder ‚Üí Local Index
   ```

2. **Search Flow**:
   ```
   User Query ‚Üí Search Engine ‚Üí Embedder ‚Üí Similarity Calc ‚Üí Ranked Results
                                             ‚Üì
                                       Local Index
   ```

3. **UI Flow**:
   ```
   Browser ‚Üî Gradio UI ‚Üî Search Engine ‚Üî Embedder
                              ‚Üì
                         Local Index
   ```

## Performance Tips

- **GPU Acceleration**: Use CUDA-enabled GPU for faster indexing and search with full models
- **Quantized Models**: Use GGUF quantized models for 4-8x memory reduction with minimal accuracy loss
  - Best for CPU-only systems or limited GPU memory
  - Q4_K_M recommended for general use
  - Text-only support (no images/videos)
- **Batch Size**: Large directories are processed in batches automatically
- **Incremental Updates**: Re-indexing only processes new or modified files
- **Model Selection**: 
  - Use quantized 2B model for fastest CPU inference
  - Use full 2B model for balanced performance with multimodal support
  - Use 8B model for best accuracy (requires more GPU memory)

## Troubleshooting

### Issue: Global keyboard shortcut not working

- On Linux: May require X11 or appropriate Wayland permissions
- On macOS: Grant accessibility permissions in System Preferences
- On Windows: May require running as administrator
- Fallback: Use the launch command without keyboard shortcut

### Issue: Out of memory during indexing

- Use CPU instead of GPU: `--device cpu`
- Index smaller directories separately
- Use the 2B model instead of 8B

### Issue: Slow search performance

- Ensure GPU is being used if available
- Consider reducing the number of indexed files
- Use smaller top_k values (fewer results)

## Quantized Models (GGUF)

The launcher supports quantized GGUF models for memory-efficient CPU inference.

### Benefits of Quantized Models

- **4-8x smaller memory footprint**: ~1.5GB vs ~6GB for 2B model
- **Faster CPU inference**: Optimized for CPU with no GPU required
- **Easy deployment**: Single file, no complex dependencies
- **Minimal accuracy loss**: Q4_K_M maintains >95% quality

### Limitations

- **Text-only**: GGUF models currently support text inputs only
- **No multimodal**: Cannot process images or videos
- For image search, use full-precision Qwen3VLEmbedder

### Download and Usage

Download quantized model:
```bash
huggingface-cli download DevQuasar/Qwen.Qwen3-VL-Embedding-2B-GGUF \
    Qwen3-VL-Embedding-2B-Q4_K_M.gguf \
    --local-dir ./models/gguf/
```

Use in launcher (automatically detected):
```bash
# Index with quantized model
python launcher.py index /path/to/docs \
    --model ./models/gguf/Qwen3-VL-Embedding-2B-Q4_K_M.gguf

# Launch with quantized model  
python launcher.py launch \
    --model ./models/gguf/Qwen3-VL-Embedding-2B-Q4_K_M.gguf \
    --device cpu
```

### Quantization Levels

| Quantization | Size | Quality | Use Case |
|-------------|------|---------|----------|
| Q4_K_M | ~1.5GB | 95% | **Recommended** - Best balance |
| Q5_K_M | ~1.8GB | 97% | Higher quality, slightly larger |
| Q8_0 | ~2.5GB | 99% | Near full quality |

## Limitations (Current MVP)

- No cloud sync or multi-device support
- No file permissions or sandboxing
- No full OS integration (e.g., system search integration)
- Limited to local file access

## Future Enhancements

Planned features for future releases:
- System-wide integration with file managers
- Cloud sync support
- Real-time file watching and auto-indexing
- Advanced filtering options
- Custom file type handlers
- Multi-index support

## License

This component follows the same Apache 2.0 license as the main Qwen3-VL-Embedding project.
